{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "# Exercise 2 - More Comparative Evaluation\n",
    "<br/>Student:\n",
    "<br/>se21m024\n",
    "<br/>Matriculation number: 1425616\n",
    "<br/>Thomas Stummer\n",
    "<br/><br/>The interpretation of the data can be found in the document <b><i>se21m024_Stummer_ml_ex2_comp_eval.pdf</i></b>.\n",
    "<br/><br/>\n",
    "The library <i>Surprise</i> (https://surprise.readthedocs.io/en/stable/index.html) was used to create the following results. The code is highly inspired by the example code provided by the libries official documentation.\n",
    "<br/><br/>\n",
    "Small data set: Heart Failure Prediction<br>\n",
    "The data set was provided by Davide Chicco, Giuseppe Jurman: Machine learning can predict survival of patients with heart failure from serum creatinine and ejection fraction alone. BMC Medical Informatics and Decision Making 20, 16 (2020) (https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-020-1023-5) and downloaded from https://www.kaggle.com/datasets/andrewmvd/heart-failure-clinical-data.\n",
    "<br/><br/>\n",
    "Big data set: Covertype<br>\n",
    "The data set was provided by Jock A. Blackard and Colorado State University and downloaded from https://archive.ics.uci.edu/ml/datasets/Covertype.\n",
    "<br/><br/>\n",
    "Music data set<br>\n",
    "Downloaded from Moodle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import glob, os\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "from collections import deque\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import neighbors\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import scipy.stats.stats as st\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import uuid\n",
    "\n",
    "# Matriculation number: 1425616\n",
    "random_state = 1425616"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_name = 'breastcancer'\n",
    "\n",
    "# Training data\n",
    "train_data_set = pd.read_csv(\".\\\\data\\\\breast-cancer-diagnostic.shuf.lrn.csv\")\n",
    "\n",
    "# Split data in input features (X) and target (y) feature\n",
    "train_data_set_X = train_data_set.loc[:,'radiusMean':]\n",
    "train_data_set_y = train_data_set.loc[:,'class']\n",
    "\n",
    "# Testing data\n",
    "test_data_set = pd.read_csv(\".\\\\data\\\\breast-cancer-diagnostic.shuf.tes.csv\")\n",
    "test_data_set_X = test_data_set.loc[:,'radiusMean':]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-NN\n",
    "# kd tree was chosen to gain results within a reasonable amount of time\n",
    "def kNN (dataSetName, X_train, X_test, y_train, y_test, n_neighbors_values):\n",
    "\n",
    "    results = []\n",
    "    bestResult = None\n",
    "\n",
    "    for n_neighbors in n_neighbors_values:\n",
    "            classifier = KNeighborsClassifier(n_neighbors=n_neighbors, algorithm='kd_tree')\n",
    "\n",
    "            # Train classifier\n",
    "            start_time = datetime.datetime.now()\n",
    "            \n",
    "            #classifier.fit(X_train, y_train.values.ravel())\n",
    "            classifier.fit(X_train, y_train.ravel())\n",
    "\n",
    "            end_time = datetime.datetime.now()\n",
    "            training_time_sec = (end_time - start_time).total_seconds()\n",
    "\n",
    "            # Predict test set on trained classifier\n",
    "            start_time = datetime.datetime.now()\n",
    "            y_test_predicted = classifier.predict(X_test)\n",
    "            end_time = datetime.datetime.now()\n",
    "            testing_time_sec = (end_time - start_time).total_seconds()\n",
    "\n",
    "            # Compute metrics\n",
    "            acc = metrics.accuracy_score(y_test, y_test_predicted)\n",
    "            f1 = f1_score(y_true=y_test, y_pred=y_test_predicted, average='weighted')\n",
    "\n",
    "            # Store results\n",
    "            result = type('',(object,),{'guid': str(uuid.uuid4()), 'classifier': classifier, 'algorithm': 'k-NN', 'n_neigbors': n_neighbors, 'training_time_sec': training_time_sec, 'testing_time_sec': testing_time_sec, 'acc': acc, 'f1': f1, 'y_test_predicted': y_test_predicted})()\n",
    "            results.append(result)\n",
    "\n",
    "            # Cache best result for confusion matrix return value\n",
    "            if(bestResult is None or bestResult.f1 < result.f1):\n",
    "                bestResult = result\n",
    "\n",
    "    # Print results\n",
    "    print(dataSetName)\n",
    "    print('GUID | Algorithm | acc | f1 | training_time_sec | testing_time_sec')\n",
    "    for res in results:\n",
    "        print(res.guid + ' | k-NN (' + str(res.n_neigbors) + '-NN) | ' + str(round(res.acc, 3)) + ' | ' + str(round(res.f1, 3)) + ' | ' + str(res.training_time_sec) + ' sec | ' + str(res.testing_time_sec) + ' sec')\n",
    "    print()\n",
    "\n",
    "    return bestResult\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree\n",
    "def decision_tree(dataSetName, X_train, X_test, y_train, y_test, max_features_values):\n",
    "\n",
    "    results = []\n",
    "    bestResult = None\n",
    "\n",
    "    for max_features in max_features_values:\n",
    "            classifier = DecisionTreeClassifier(max_features=max_features, random_state=random_state) \n",
    "\n",
    "            # Train classifier\n",
    "            start_time = datetime.datetime.now()\n",
    "            classifier.fit(X_train, y_train.ravel())\n",
    "            end_time = datetime.datetime.now()\n",
    "            training_time_sec = (end_time - start_time).total_seconds()\n",
    "\n",
    "            # Predict test set on trained classifier\n",
    "            start_time = datetime.datetime.now()\n",
    "            y_test_predicted = classifier.predict(X_test)\n",
    "            end_time = datetime.datetime.now()\n",
    "            testing_time_sec = (end_time - start_time).total_seconds()\n",
    "\n",
    "            # Compute metrics\n",
    "            acc = metrics.accuracy_score(y_test, y_test_predicted)\n",
    "            f1 = f1_score(y_true=y_test, y_pred=y_test_predicted, average='weighted')\n",
    "\n",
    "            # Store results\n",
    "            result = type('',(object,),{'guid': str(uuid.uuid4()), 'classifier': classifier, 'algorithm': 'decision_tree', 'max_features': max_features, 'training_time_sec': training_time_sec, 'testing_time_sec': testing_time_sec, 'acc': acc, 'f1': f1, 'y_test_predicted': y_test_predicted})()\n",
    "            results.append(result)\n",
    "\n",
    "            # Cache best result for confusion matrix return value\n",
    "            if(bestResult is None or bestResult.f1 < result.f1):\n",
    "                bestResult = result\n",
    "\n",
    "    # Print results\n",
    "    print(dataSetName)\n",
    "    print('GUID | Algorithm | acc | f1 | training_time_sec | testing_time_sec')\n",
    "    for res in results:\n",
    "        print(res.guid + ' | Decision Tree (max features: ' + str(res.max_features) + ') | ' + str(round(res.acc, 3)) + ' | ' + str(round(res.f1, 3)) + ' | ' + str(res.training_time_sec) + ' sec | ' + str(res.testing_time_sec) + ' sec')\n",
    "    print()\n",
    "\n",
    "    return bestResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm\n",
    "def svm_svc(dataSetName, X_train, X_test, y_train, y_test):\n",
    "\n",
    "    results = []\n",
    "    bestResult = None\n",
    "    classifier = make_pipeline(StandardScaler(), SVC(random_state=random_state))\n",
    "\n",
    "    # Train classifier\n",
    "    start_time = datetime.datetime.now()\n",
    "    classifier.fit(X_train, y_train.ravel())\n",
    "    end_time = datetime.datetime.now()\n",
    "    training_time_sec = (end_time - start_time).total_seconds()\n",
    "\n",
    "    # Predict test set on trained classifier\n",
    "    start_time = datetime.datetime.now()\n",
    "    y_test_predicted = classifier.predict(X_test)\n",
    "    end_time = datetime.datetime.now()\n",
    "    testing_time_sec = (end_time - start_time).total_seconds()\n",
    "\n",
    "    # Compute metrics\n",
    "    acc = metrics.accuracy_score(y_test, y_test_predicted)\n",
    "    f1 = f1_score(y_true=y_test, y_pred=y_test_predicted, average='weighted')\n",
    "\n",
    "    # Store results\n",
    "    result = type('',(object,),{'guid': str(uuid.uuid4()), 'classifier': classifier, 'algorithm': 'svm', 'training_time_sec': training_time_sec, 'testing_time_sec': testing_time_sec, 'acc': acc, 'f1': f1, 'y_test_predicted': y_test_predicted})()\n",
    "    results.append(result)\n",
    "\n",
    "    # Cache best result for confusion matrix return value\n",
    "    if(bestResult is None or bestResult.f1 < result.f1):\n",
    "        bestResult = result\n",
    "\n",
    "    # Print results\n",
    "    print(dataSetName)\n",
    "    print('GUID | Algorithm | acc | f1 | training_time_sec | testing_time_sec')\n",
    "    for res in results:\n",
    "        print(res.guid + ' | SVM | ' + str(round(res.acc, 3)) + ' | ' + str(round(res.f1, 3)) + ' | ' + str(res.training_time_sec) + ' sec | ' + str(res.testing_time_sec) + ' sec')\n",
    "    print()\n",
    "\n",
    "    return bestResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forests\n",
    "def random_forests(dataSetName, X_train, X_test, y_train, y_test, numbers_of_trees, max_features_values):\n",
    "\n",
    "    results = []\n",
    "    bestResult = None\n",
    "\n",
    "    for number_of_trees in numbers_of_trees:\n",
    "        for max_features in max_features_values:\n",
    "\n",
    "            classifier = RandomForestClassifier(n_estimators=number_of_trees, max_features=max_features, random_state=random_state)\n",
    "\n",
    "            # Train classifier\n",
    "            start_time = datetime.datetime.now()\n",
    "            classifier.fit(X_train, y_train.ravel())\n",
    "            end_time = datetime.datetime.now()\n",
    "            training_time_sec = (end_time - start_time).total_seconds()\n",
    "\n",
    "            # Predict test set on trained classifier\n",
    "            start_time = datetime.datetime.now()\n",
    "            y_test_predicted = classifier.predict(X_test)\n",
    "            end_time = datetime.datetime.now()\n",
    "            testing_time_sec = (end_time - start_time).total_seconds()\n",
    "\n",
    "            # Compute metrics\n",
    "            acc = metrics.accuracy_score(y_test, y_test_predicted)\n",
    "            f1 = f1_score(y_true=y_test, y_pred=y_test_predicted, average='weighted')\n",
    "\n",
    "            # Store results\n",
    "            result = type('',(object,),{'guid': str(uuid.uuid4()), 'classifier': classifier, 'algorithm': 'random_forests', 'number_of_trees': number_of_trees, 'max_features': max_features, 'training_time_sec': training_time_sec, 'testing_time_sec': testing_time_sec, 'acc': acc, 'f1': f1, 'y_test_predicted': y_test_predicted})()\n",
    "            results.append(result)\n",
    "\n",
    "            # Cache best result for confusion matrix return value\n",
    "            if(bestResult is None or bestResult.f1 < result.f1):\n",
    "                bestResult = result\n",
    "\n",
    "    # Print results\n",
    "    print(dataSetName)\n",
    "    print('GUID | Algorithm | acc | f1 | training_time_sec | testing_time_sec')\n",
    "    for res in results:\n",
    "        print(res.guid + ' | Random Forests (num trees: ' + str(res.number_of_trees) + ', max features: ' + str(res.max_features) + ') | ' + str(round(res.acc, 3)) + ' | ' + str(round(res.f1, 3)) + ' | ' + str(res.training_time_sec) + ' sec | ' + str(res.testing_time_sec) + ' sec')\n",
    "    print()\n",
    "\n",
    "    return bestResult\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breastcancer\n",
      "GUID | Algorithm | acc | f1 | training_time_sec | testing_time_sec\n",
      "b7339775-5b02-4ec2-98c7-21361528feef | k-NN (1-NN) | 0.874 | 0.873 | 0.001621 sec | 0.004197 sec\n",
      "32155a27-c70f-43ea-95ba-5dd0db44db0b | k-NN (2-NN) | 0.895 | 0.893 | 0.00199 sec | 0.005608 sec\n",
      "30110ab7-c0d0-4fe3-9cb7-5c8c3ef87437 | k-NN (3-NN) | 0.884 | 0.884 | 0.001978 sec | 0.004641 sec\n",
      "\n",
      "breastcancer\n",
      "GUID | Algorithm | acc | f1 | training_time_sec | testing_time_sec\n",
      "7e3bdd85-eb03-4702-88c6-5629cddced19 | Decision Tree (max features: None) | 0.937 | 0.937 | 0.003462 sec | 0.001615 sec\n",
      "48d52371-2c6d-4274-8042-77bd6f3db547 | Decision Tree (max features: sqrt) | 0.937 | 0.937 | 0.001694 sec | 0.000944 sec\n",
      "819b7c3c-c459-4433-8f88-71a102ae9bf3 | Decision Tree (max features: log2) | 0.947 | 0.947 | 0.00305 sec | 0.002 sec\n",
      "\n",
      "breastcancer\n",
      "GUID | Algorithm | acc | f1 | training_time_sec | testing_time_sec\n",
      "f70aa554-c0d7-4409-bab7-7d4e00947f89 | SVM | 0.968 | 0.968 | 0.007003 sec | 0.000997 sec\n",
      "\n",
      "breastcancer\n",
      "GUID | Algorithm | acc | f1 | training_time_sec | testing_time_sec\n",
      "a83533df-2b8a-4bde-a109-b891e9f19ec7 | Random Forests (num trees: 10, max features: sqrt) | 0.968 | 0.968 | 0.013999 sec | 0.002 sec\n",
      "69c736e8-af59-45a0-8e69-9902ba9c8f59 | Random Forests (num trees: 10, max features: log2) | 0.968 | 0.968 | 0.01396 sec | 0.002036 sec\n",
      "84b775fe-43fc-4011-a010-804f8eedb9f0 | Random Forests (num trees: 100, max features: sqrt) | 0.958 | 0.958 | 0.118003 sec | 0.008467 sec\n",
      "1b3f0b35-066a-4eeb-b91d-0e3eab983e26 | Random Forests (num trees: 100, max features: log2) | 0.968 | 0.968 | 0.120834 sec | 0.008104 sec\n",
      "\n",
      "GUID of best classifier: f70aa554-c0d7-4409-bab7-7d4e00947f89\n"
     ]
    }
   ],
   "source": [
    "def kNN_with_parameters(data_set_name, X_train, X_test, y_train, y_test):\n",
    "    n_neighbors_values = [1, 2, 3]\n",
    "    return kNN(data_set_name, X_train, X_test, y_train, y_test, n_neighbors_values)\n",
    "\n",
    "def decision_tree_with_parameters(data_set_name, X_train, X_test, y_train, y_test):\n",
    "    max_features_values = [None, 'sqrt', 'log2'] \n",
    "    return decision_tree(data_set_name, X_train, X_test, y_train, y_test, max_features_values)\n",
    "\n",
    "def random_forests_with_parameters(data_set_name, X_train, X_test, y_train, y_test):\n",
    "    numbers_of_trees = [10, 100]\n",
    "    max_features_values = ['sqrt', 'log2'] \n",
    "    return random_forests(data_set_name, X_train, X_test, y_train, y_test, numbers_of_trees, max_features_values)\n",
    "\n",
    "classifiers = [\n",
    "                kNN_with_parameters,\n",
    "                decision_tree_with_parameters,\n",
    "                svm_svc,\n",
    "                random_forests_with_parameters\n",
    "              ]\n",
    "\n",
    "bestResult = None\n",
    "\n",
    "X, y = shuffle(train_data_set_X, train_data_set_y, random_state=random_state)\n",
    "\n",
    "# Prepare a train/test set split: split 2/3 1/3 into training & test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=random_state)\n",
    "\n",
    "for indexClassifier, classifier in enumerate(classifiers):\n",
    "    # do the actual classification\n",
    "    result = classifier(data_set_name, X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # Cache best result for confusion matrix return value\n",
    "    if(bestResult is None or bestResult.f1 < result.f1):\n",
    "        bestResult = result\n",
    "        bestResult.y_test = y_test\n",
    "\n",
    "# Use best performing model for prediction on the test set\n",
    "print('GUID of best classifier: ' + bestResult.guid)\n",
    "test_predicted = bestResult.classifier.predict(test_data_set_X)\n",
    "predicted_csv = list(zip(*[test_data_set.loc[:,'ID'], [str(x).lower() for x in test_predicted]]))\n",
    "np.savetxt(data_set_name + '_prediction.csv', \n",
    "           predicted_csv,\n",
    "           header='ID,class',\n",
    "           comments='',\n",
    "           delimiter =\",\", \n",
    "           fmt ='%s')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

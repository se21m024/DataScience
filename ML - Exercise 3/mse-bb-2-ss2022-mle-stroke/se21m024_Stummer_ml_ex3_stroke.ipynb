{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "# Exercise 3 - Kaggle competition\n",
    "<br/>Student:\n",
    "<br/>se21m024\n",
    "<br/>Matriculation number: 1425616\n",
    "<br/>Thomas Stummer\n",
    "<br/><br/>The interpretation of the data can be found in the document <b><i>se21m024_Stummer_ml_ex3_stroke.pdf</i></b>.\n",
    "<br/><br/>\n",
    "Large data set: Stroke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import glob, os\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "from collections import deque\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import neighbors\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import scipy.stats.stats as st\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import uuid\n",
    "\n",
    "# Matriculation number: 1425616\n",
    "random_state = 1425616\n",
    "use_kaggle_paths = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_name = 'stroke'\n",
    "\n",
    "def map_to_numeric_value(data_set, column_name):\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    label_encoder.fit(data_set[column_name])\n",
    "    data_set[column_name] = label_encoder.transform(data_set[column_name])\n",
    "    return data_set\n",
    "\n",
    "def encode_string_feature_values(data_set):\n",
    "    data_set = map_to_numeric_value(data_set, 'gender')\n",
    "    data_set = map_to_numeric_value(data_set, 'ever_married')\n",
    "    data_set = map_to_numeric_value(data_set, 'work_type')\n",
    "    data_set = map_to_numeric_value(data_set, 'Residence_type')\n",
    "    data_set = map_to_numeric_value(data_set, 'smoking_status')\n",
    "    data_set = data_set.fillna(0)\n",
    "    return data_set\n",
    "\n",
    "# Training data\n",
    "train_data_set_file = \".\\\\data\\\\stroke.shuf.lrn.csv\" # Local dev\n",
    "if use_kaggle_paths:\n",
    "    train_data_set_file = \"../input/mse-bb-2-ss2022-mle-stroke/stroke.shuf.lrn.csv\"  # Kaggle\n",
    "\n",
    "train_data_set = pd.read_csv(train_data_set_file)\n",
    "\n",
    "# Map non-numeric features to numeric values\n",
    "train_data_set = encode_string_feature_values(train_data_set)\n",
    "\n",
    "# Split data in input features (X) and target (y) feature\n",
    "train_data_set_X = train_data_set.loc[:,'gender':'smoking_status']\n",
    "train_data_set_y = train_data_set.loc[:,'stroke']\n",
    "\n",
    "# Testing data\n",
    "test_data_set_file = \".\\\\data\\\\stroke.shuf.tes.csv\" # Local dev\n",
    "if use_kaggle_paths:\n",
    "    test_data_set_file = \"../input/mse-bb-2-ss2022-mle-stroke/stroke.shuf.tes.csv\"  # Kaggle\n",
    "    \n",
    "test_data_set = pd.read_csv(test_data_set_file)\n",
    "\n",
    "# Map non-numeric features to numeric values\n",
    "test_data_set = encode_string_feature_values(test_data_set)\n",
    "\n",
    "test_data_set_X = test_data_set.loc[:,'gender':]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-NN\n",
    "# kd tree was chosen to gain results within a reasonable amount of time\n",
    "def kNN (dataSetName, X_train, X_test, y_train, y_test, n_neighbors_values):\n",
    "\n",
    "    results = []\n",
    "    bestResult = None\n",
    "\n",
    "    for n_neighbors in n_neighbors_values:\n",
    "            classifier = KNeighborsClassifier(n_neighbors=n_neighbors, algorithm='kd_tree')\n",
    "\n",
    "            # Train classifier\n",
    "            start_time = datetime.datetime.now()\n",
    "            \n",
    "            #classifier.fit(X_train, y_train.values.ravel())\n",
    "            classifier.fit(X_train, y_train.ravel())\n",
    "\n",
    "            end_time = datetime.datetime.now()\n",
    "            training_time_sec = (end_time - start_time).total_seconds()\n",
    "\n",
    "            # Predict test set on trained classifier\n",
    "            start_time = datetime.datetime.now()\n",
    "            y_test_predicted = classifier.predict(X_test)\n",
    "            end_time = datetime.datetime.now()\n",
    "            testing_time_sec = (end_time - start_time).total_seconds()\n",
    "\n",
    "            # Compute metrics\n",
    "            acc = metrics.accuracy_score(y_test, y_test_predicted)\n",
    "            f1 = f1_score(y_true=y_test, y_pred=y_test_predicted, average='weighted')\n",
    "\n",
    "            # Store results\n",
    "            result = type('',(object,),{'guid': str(uuid.uuid4()), 'classifier': classifier, 'algorithm': 'k-NN', 'n_neigbors': n_neighbors, 'training_time_sec': training_time_sec, 'testing_time_sec': testing_time_sec, 'acc': acc, 'f1': f1, 'y_test_predicted': y_test_predicted})()\n",
    "            results.append(result)\n",
    "\n",
    "            # Cache best result for confusion matrix return value\n",
    "            if(bestResult is None or bestResult.f1 < result.f1):\n",
    "                bestResult = result\n",
    "\n",
    "    # Print results\n",
    "    print(dataSetName)\n",
    "    print('GUID | Algorithm | acc | f1 | training_time_sec | testing_time_sec')\n",
    "    for res in results:\n",
    "        print(res.guid + ' | k-NN (' + str(res.n_neigbors) + '-NN) | ' + str(round(res.acc, 3)) + ' | ' + str(round(res.f1, 3)) + ' | ' + str(res.training_time_sec) + ' sec | ' + str(res.testing_time_sec) + ' sec')\n",
    "    print()\n",
    "\n",
    "    return bestResult\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree\n",
    "def decision_tree(dataSetName, X_train, X_test, y_train, y_test, max_features_values):\n",
    "\n",
    "    results = []\n",
    "    bestResult = None\n",
    "\n",
    "    for max_features in max_features_values:\n",
    "            classifier = DecisionTreeClassifier(max_features=max_features, random_state=random_state) \n",
    "\n",
    "            # Train classifier\n",
    "            start_time = datetime.datetime.now()\n",
    "            classifier.fit(X_train, y_train.ravel())\n",
    "            end_time = datetime.datetime.now()\n",
    "            training_time_sec = (end_time - start_time).total_seconds()\n",
    "\n",
    "            # Predict test set on trained classifier\n",
    "            start_time = datetime.datetime.now()\n",
    "            y_test_predicted = classifier.predict(X_test)\n",
    "            end_time = datetime.datetime.now()\n",
    "            testing_time_sec = (end_time - start_time).total_seconds()\n",
    "\n",
    "            # Compute metrics\n",
    "            acc = metrics.accuracy_score(y_test, y_test_predicted)\n",
    "            f1 = f1_score(y_true=y_test, y_pred=y_test_predicted, average='weighted')\n",
    "\n",
    "            # Store results\n",
    "            result = type('',(object,),{'guid': str(uuid.uuid4()), 'classifier': classifier, 'algorithm': 'decision_tree', 'max_features': max_features, 'training_time_sec': training_time_sec, 'testing_time_sec': testing_time_sec, 'acc': acc, 'f1': f1, 'y_test_predicted': y_test_predicted})()\n",
    "            results.append(result)\n",
    "\n",
    "            # Cache best result for confusion matrix return value\n",
    "            if(bestResult is None or bestResult.f1 < result.f1):\n",
    "                bestResult = result\n",
    "\n",
    "    # Print results\n",
    "    print(dataSetName)\n",
    "    print('GUID | Algorithm | acc | f1 | training_time_sec | testing_time_sec')\n",
    "    for res in results:\n",
    "        print(res.guid + ' | Decision Tree (max features: ' + str(res.max_features) + ') | ' + str(round(res.acc, 3)) + ' | ' + str(round(res.f1, 3)) + ' | ' + str(res.training_time_sec) + ' sec | ' + str(res.testing_time_sec) + ' sec')\n",
    "    print()\n",
    "\n",
    "    return bestResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm\n",
    "def svm_svc(dataSetName, X_train, X_test, y_train, y_test):\n",
    "\n",
    "    results = []\n",
    "    bestResult = None\n",
    "    classifier = make_pipeline(StandardScaler(), SVC(random_state=random_state))\n",
    "\n",
    "    # Train classifier\n",
    "    start_time = datetime.datetime.now()\n",
    "    classifier.fit(X_train, y_train.ravel())\n",
    "    end_time = datetime.datetime.now()\n",
    "    training_time_sec = (end_time - start_time).total_seconds()\n",
    "\n",
    "    # Predict test set on trained classifier\n",
    "    start_time = datetime.datetime.now()\n",
    "    y_test_predicted = classifier.predict(X_test)\n",
    "    end_time = datetime.datetime.now()\n",
    "    testing_time_sec = (end_time - start_time).total_seconds()\n",
    "\n",
    "    # Compute metrics\n",
    "    acc = metrics.accuracy_score(y_test, y_test_predicted)\n",
    "    f1 = f1_score(y_true=y_test, y_pred=y_test_predicted, average='weighted')\n",
    "\n",
    "    # Store results\n",
    "    result = type('',(object,),{'guid': str(uuid.uuid4()), 'classifier': classifier, 'algorithm': 'svm', 'training_time_sec': training_time_sec, 'testing_time_sec': testing_time_sec, 'acc': acc, 'f1': f1, 'y_test_predicted': y_test_predicted})()\n",
    "    results.append(result)\n",
    "\n",
    "    # Cache best result for confusion matrix return value\n",
    "    if(bestResult is None or bestResult.f1 < result.f1):\n",
    "        bestResult = result\n",
    "\n",
    "    # Print results\n",
    "    print(dataSetName)\n",
    "    print('GUID | Algorithm | acc | f1 | training_time_sec | testing_time_sec')\n",
    "    for res in results:\n",
    "        print(res.guid + ' | SVM | ' + str(round(res.acc, 3)) + ' | ' + str(round(res.f1, 3)) + ' | ' + str(res.training_time_sec) + ' sec | ' + str(res.testing_time_sec) + ' sec')\n",
    "    print()\n",
    "\n",
    "    return bestResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forests\n",
    "def random_forests(dataSetName, X_train, X_test, y_train, y_test, numbers_of_trees, max_features_values):\n",
    "\n",
    "    results = []\n",
    "    bestResult = None\n",
    "\n",
    "    for number_of_trees in numbers_of_trees:\n",
    "        for max_features in max_features_values:\n",
    "\n",
    "            classifier = RandomForestClassifier(n_estimators=number_of_trees, max_features=max_features, random_state=random_state)\n",
    "\n",
    "            # Train classifier\n",
    "            start_time = datetime.datetime.now()\n",
    "            classifier.fit(X_train, y_train.ravel())\n",
    "            end_time = datetime.datetime.now()\n",
    "            training_time_sec = (end_time - start_time).total_seconds()\n",
    "\n",
    "            # Predict test set on trained classifier\n",
    "            start_time = datetime.datetime.now()\n",
    "            y_test_predicted = classifier.predict(X_test)\n",
    "            end_time = datetime.datetime.now()\n",
    "            testing_time_sec = (end_time - start_time).total_seconds()\n",
    "\n",
    "            # Compute metrics\n",
    "            acc = metrics.accuracy_score(y_test, y_test_predicted)\n",
    "            f1 = f1_score(y_true=y_test, y_pred=y_test_predicted, average='weighted')\n",
    "\n",
    "            # Store results\n",
    "            result = type('',(object,),{'guid': str(uuid.uuid4()), 'classifier': classifier, 'algorithm': 'random_forests', 'number_of_trees': number_of_trees, 'max_features': max_features, 'training_time_sec': training_time_sec, 'testing_time_sec': testing_time_sec, 'acc': acc, 'f1': f1, 'y_test_predicted': y_test_predicted})()\n",
    "            results.append(result)\n",
    "\n",
    "            # Cache best result for confusion matrix return value\n",
    "            if(bestResult is None or bestResult.f1 < result.f1):\n",
    "                bestResult = result\n",
    "\n",
    "    # Print results\n",
    "    print(dataSetName)\n",
    "    print('GUID | Algorithm | acc | f1 | training_time_sec | testing_time_sec')\n",
    "    for res in results:\n",
    "        print(res.guid + ' | Random Forests (num trees: ' + str(res.number_of_trees) + ', max features: ' + str(res.max_features) + ') | ' + str(round(res.acc, 3)) + ' | ' + str(round(res.f1, 3)) + ' | ' + str(res.training_time_sec) + ' sec | ' + str(res.testing_time_sec) + ' sec')\n",
    "    print()\n",
    "\n",
    "    return bestResult\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find best Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stroke\n",
      "GUID | Algorithm | acc | f1 | training_time_sec | testing_time_sec\n",
      "4bd62aab-a565-4df4-be82-a8909ac2aa50 | k-NN (1-NN) | 0.917 | 0.921 | 0.007 sec | 0.024 sec\n",
      "eda1091a-31c4-49c8-abe7-120df1d827f4 | k-NN (2-NN) | 0.954 | 0.936 | 0.003999 sec | 0.022003 sec\n",
      "6fd019b6-8b6c-468e-9b32-5622c686b035 | k-NN (3-NN) | 0.947 | 0.932 | 0.003999 sec | 0.023002 sec\n",
      "\n",
      "stroke\n",
      "GUID | Algorithm | acc | f1 | training_time_sec | testing_time_sec\n",
      "39cdc296-432b-4036-b53f-45466353ca63 | Decision Tree (max features: None) | 0.929 | 0.931 | 0.004999 sec | 0.002001 sec\n",
      "2c9628c5-f8cc-493b-9125-69e3ac8e54c0 | Decision Tree (max features: sqrt) | 0.919 | 0.919 | 0.001999 sec | 0.002004 sec\n",
      "aebd1b76-62ff-4df7-81db-8335ad361ae5 | Decision Tree (max features: log2) | 0.919 | 0.919 | 0.002998 sec | 0.001001 sec\n",
      "\n",
      "stroke\n",
      "GUID | Algorithm | acc | f1 | training_time_sec | testing_time_sec\n",
      "37914454-fddb-4789-8d53-076e9279b441 | SVM | 0.956 | 0.935 | 0.023999 sec | 0.005998 sec\n",
      "\n",
      "stroke\n",
      "GUID | Algorithm | acc | f1 | training_time_sec | testing_time_sec\n",
      "67d50204-1e07-4de1-a2aa-811a46f9d5c9 | Random Forests (num trees: 10, max features: sqrt) | 0.953 | 0.933 | 0.020002 sec | 0.003 sec\n",
      "25f88344-0eb7-4f4f-b432-4881dc5a4b02 | Random Forests (num trees: 10, max features: log2) | 0.953 | 0.933 | 0.020005 sec | 0.002998 sec\n",
      "f91addde-fd4d-47c9-8d57-5aee9edbc643 | Random Forests (num trees: 100, max features: sqrt) | 0.955 | 0.934 | 0.177032 sec | 0.015001 sec\n",
      "20a16f02-5320-4eec-8ed4-7f6f45ed4228 | Random Forests (num trees: 100, max features: log2) | 0.955 | 0.934 | 0.17297 sec | 0.016034 sec\n",
      "\n",
      "GUID of best classifier: eda1091a-31c4-49c8-abe7-120df1d827f4\n"
     ]
    }
   ],
   "source": [
    "def kNN_with_parameters(data_set_name, X_train, X_test, y_train, y_test):\n",
    "    n_neighbors_values = [1, 2, 3]\n",
    "    return kNN(data_set_name, X_train, X_test, y_train, y_test, n_neighbors_values)\n",
    "\n",
    "def decision_tree_with_parameters(data_set_name, X_train, X_test, y_train, y_test):\n",
    "    max_features_values = [None, 'sqrt', 'log2'] \n",
    "    return decision_tree(data_set_name, X_train, X_test, y_train, y_test, max_features_values)\n",
    "\n",
    "def random_forests_with_parameters(data_set_name, X_train, X_test, y_train, y_test):\n",
    "    numbers_of_trees = [10, 100]\n",
    "    max_features_values = ['sqrt', 'log2'] \n",
    "    return random_forests(data_set_name, X_train, X_test, y_train, y_test, numbers_of_trees, max_features_values)\n",
    "\n",
    "classifiers = [\n",
    "                kNN_with_parameters,\n",
    "                decision_tree_with_parameters,\n",
    "                svm_svc,\n",
    "                random_forests_with_parameters\n",
    "              ]\n",
    "\n",
    "bestResult = None\n",
    "\n",
    "X, y = shuffle(train_data_set_X, train_data_set_y, random_state=random_state)\n",
    "\n",
    "# Prepare a train/test set split: split 2/3 1/3 into training & test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=random_state)\n",
    "\n",
    "for indexClassifier, classifier in enumerate(classifiers):\n",
    "    # do the actual classification\n",
    "    result = classifier(data_set_name, X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # Cache best result for confusion matrix return value\n",
    "    if(bestResult is None or bestResult.f1 < result.f1):\n",
    "        bestResult = result\n",
    "        bestResult.y_test = y_test\n",
    "\n",
    "print('GUID of best classifier: ' + bestResult.guid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain best Classifier and create Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved prediction file stroke_prediction_2022-06-05_10-25-13_utc.csv\n"
     ]
    }
   ],
   "source": [
    "# Retrain best performing model on the whole training set\n",
    "bestResult.classifier.fit(X, y.ravel())\n",
    "\n",
    "# Create prediction for the test set\n",
    "test_predicted = bestResult.classifier.predict(test_data_set_X)\n",
    "predicted_csv = list(zip(*[test_data_set.loc[:,'ID'], [str(x).lower() for x in test_predicted]]))\n",
    "\n",
    "# Save prediction in file\n",
    "csv_file_path = data_set_name + '_prediction_' + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\") + '_utc.csv'\n",
    "np.savetxt(csv_file_path, \n",
    "           predicted_csv,\n",
    "           header='ID,stroke',\n",
    "           comments='',\n",
    "           delimiter =\",\", \n",
    "           fmt ='%s')\n",
    "\n",
    "print('Saved prediction file ' + csv_file_path)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import glob, os\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from librosa import display\n",
    "import librosa\n",
    "import numpy as np\n",
    "import datetime\n",
    "from collections import deque\n",
    "import progressbar\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import neighbors\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import scipy.stats.stats as st\n",
    "\n",
    "# Matriculation number: 01425616\n",
    "random_state = 1425616"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22 files\n",
      "\n",
      "Found the following classes: ['disco', 'metal']\n",
      "Transformed labels (first elements: [0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1]\n",
      "... done label encoding\n"
     ]
    }
   ],
   "source": [
    "# We need to construct our data set; unfortunately, we don't simply have a \"loadGTZanDataSet()\" function in SK-learn...\n",
    "# So we need to \n",
    "## Download our data set & extract it (one-time effort)\n",
    "## Run an audio feature extraction\n",
    "## Create the create the ground truth (label assignment, target, ...) \n",
    "\n",
    "\n",
    "# path to our audio folder\n",
    "# For the first run, download the images from http://kronos.ifs.tuwien.ac.at/GTZANmp3_22khz.zip, and unzip them to your folder\n",
    "#imagePath=\"../../ML_Data/GTZANmp3_22khz/\"\n",
    "imagePath=\"..\\\\..\\\\ML_Data\\\\GTZANmp3_22khz_sub\\\\\"\n",
    "\n",
    "\n",
    "# Find all songs in that folder; there are like 1.000 different ways to do this in Python, we chose this one :-)\n",
    "os.chdir(imagePath)\n",
    "fileNames = glob.glob(\"*/*.mp3\")\n",
    "numberOfFiles=len(fileNames)\n",
    "targetLabels=[]\n",
    "\n",
    "print( 'Found ' + str(numberOfFiles) + \" files\\n\")\n",
    "\n",
    "# The first step - create the ground truth (label assignment, target, ...) \n",
    "# For that, iterate over the files, and obtain the class label for each file\n",
    "# Basically, the class name is in the full path name, so we simply use that\n",
    "for fileName in fileNames:\n",
    "    pathSepIndex = fileName.index(\"\\\\\")\n",
    "    targetLabels.append(fileName[:pathSepIndex])\n",
    "\n",
    "# sk-learn can only handle labels in numeric format - we have them as strings though...\n",
    "# Thus we use the LabelEncoder, which does a mapping to Integer numbers\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(targetLabels) # this basically finds all unique class names, and assigns them to the numbers\n",
    "print( \"Found the following classes: \" + str(list(le.classes_)))\n",
    "\n",
    "# now we transform our labels to integers\n",
    "target = le.transform(targetLabels); \n",
    "print( \"Transformed labels (first elements: \" + str(target[0:150]))\n",
    "\n",
    "# If we want to find again the label for an integer value, we can do something like this:\n",
    "# print list(le.inverse_transform([0, 18, 1]))\n",
    "\n",
    "print( \"... done label encoding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features using librosa (2022-05-22 12:26:39.104238)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n",
      "  0% (0 of 22) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--\n",
      "  4% (1 of 22) |#                        | Elapsed Time: 0:00:03 ETA:   0:01:11\n",
      "  9% (2 of 22) |##                       | Elapsed Time: 0:00:06 ETA:   0:01:09\n",
      " 13% (3 of 22) |###                      | Elapsed Time: 0:00:10 ETA:   0:01:05\n",
      " 18% (4 of 22) |####                     | Elapsed Time: 0:00:13 ETA:   0:01:02\n",
      " 22% (5 of 22) |#####                    | Elapsed Time: 0:00:17 ETA:   0:00:58\n",
      " 27% (6 of 22) |######                   | Elapsed Time: 0:00:20 ETA:   0:00:54\n",
      " 31% (7 of 22) |#######                  | Elapsed Time: 0:00:24 ETA:   0:00:50\n",
      " 36% (8 of 22) |#########                | Elapsed Time: 0:00:27 ETA:   0:00:47\n",
      " 40% (9 of 22) |##########               | Elapsed Time: 0:00:30 ETA:   0:00:45\n",
      " 45% (10 of 22) |##########              | Elapsed Time: 0:00:34 ETA:   0:00:42\n",
      " 50% (11 of 22) |############            | Elapsed Time: 0:00:38 ETA:   0:00:39\n",
      " 54% (12 of 22) |#############           | Elapsed Time: 0:00:41 ETA:   0:00:35\n",
      " 59% (13 of 22) |##############          | Elapsed Time: 0:00:45 ETA:   0:00:31\n",
      " 63% (14 of 22) |###############         | Elapsed Time: 0:00:48 ETA:   0:00:28\n",
      " 68% (15 of 22) |################        | Elapsed Time: 0:00:52 ETA:   0:00:24\n",
      " 72% (16 of 22) |#################       | Elapsed Time: 0:00:55 ETA:   0:00:21\n",
      " 77% (17 of 22) |##################      | Elapsed Time: 0:00:59 ETA:   0:00:17\n",
      " 81% (18 of 22) |###################     | Elapsed Time: 0:01:02 ETA:   0:00:15\n",
      " 86% (19 of 22) |####################    | Elapsed Time: 0:01:06 ETA:   0:00:10\n",
      " 90% (20 of 22) |#####################   | Elapsed Time: 0:01:10 ETA:   0:00:07\n",
      " 95% (21 of 22) |######################  | Elapsed Time: 0:01:13 ETA:   0:00:03\n",
      "100% (22 of 22) |########################| Elapsed Time: 0:01:13 Time:  0:01:13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".... done (2022-05-22 12:27:56.156840)\n"
     ]
    }
   ],
   "source": [
    "# Now we do the actual feature extraction\n",
    "\n",
    "# This is a helper function that computes the differences between adjacent array values\n",
    "def differences(seq):\n",
    "    iterable = iter(seq)\n",
    "    prev = next(iterable)\n",
    "    for element in iterable:\n",
    "        yield element - prev\n",
    "        prev = element\n",
    "\n",
    "# This is a helper function that computes various statistical moments over a series of values, including mean, median, var, min, max, skewness and kurtosis (a total of 7 values)\n",
    "def statistics(numericList):\n",
    "    return [np.mean(numericList), np.median(numericList), np.var(numericList), np.float64(st.skew(numericList)), np.float64(st.kurtosis(numericList)), np.min(numericList), np.max(numericList)]\n",
    "\n",
    "\n",
    "\n",
    "print( \"Extracting features using librosa\" + \" (\" + str(datetime.datetime.now()) + \")\")\n",
    "\n",
    "# compute some features based on BPMs, MFCCs, Chroma\n",
    "data_bpm=[]\n",
    "data_bpm_statistics=[]\n",
    "data_mfcc=[]\n",
    "data_chroma=[]\n",
    "\n",
    "# This takes a bit, so let's show it with a progress bar\n",
    "with progressbar.ProgressBar(max_value=len(fileNames)) as bar:\n",
    "    for indexSample, fileName in enumerate(fileNames):\n",
    "        # Load the audio as a waveform `y`, store the sampling rate as `sr`\n",
    "        y, sr = librosa.load(fileName)\n",
    "\n",
    "        # run the default beat tracker\n",
    "        tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr)\n",
    "        # from this, we simply use the tempo as BPM feature\n",
    "        data_bpm.append([tempo])\n",
    "\n",
    "        # Then we compute a few statistics on the beat timings\n",
    "        beat_times = librosa.frames_to_time(beat_frames, sr=sr)\n",
    "        # from the timings, compute the time differences between the beats\n",
    "        beat_intervals = np.array(deque(differences(beat_times)))\n",
    "\n",
    "        # And from this, take some statistics\n",
    "        # There might be a few files where the beat timings are not determined properly; we ignore them, resp. give them 0 values\n",
    "        if len(beat_intervals) < 1:\n",
    "            print( \"Errors with beat interval in file \" + fileName + \", index \" + str(indexSample) + \", using 0 values instead\")\n",
    "            data_bpm_statistics.append([tempo, 0, 0, 0, 0, 0, 0, 0])\n",
    "        else:\n",
    "            bpm_statisticsVector=[]\n",
    "            bpm_statisticsVector.append(tempo) # we also include the raw value of tempo\n",
    "            for stat in statistics(beat_intervals):  # in case the timings are ok, we actually compute the statistics\n",
    "                bpm_statisticsVector.append(stat) # and append it to the vector, which finally has 1 + 7 features\n",
    "            data_bpm_statistics.append(bpm_statisticsVector)\n",
    "\n",
    "        # Next feature are MFCCs; we take 12 coefficients; for each coefficient, we have around 40 values per second\n",
    "        mfccs=librosa.feature.mfcc(y=y, sr=sr, n_mfcc=12)\n",
    "        mfccVector=[]\n",
    "        for mfccCoefficient in mfccs: # we transform this time series by taking again statistics over the values\n",
    "            mfccVector.append(statistics(mfccCoefficient))\n",
    "\n",
    "        # Finally, this vector should have 12 * 7 features\n",
    "        data_mfcc.append(np.array(mfccVector).flatten())\n",
    "\n",
    "\n",
    "        # Last feature set - chroma (which is roughly similar to actual notes)\n",
    "        chroma=librosa.feature.chroma_stft(y=y, sr=sr);\n",
    "        chromaVector=[]\n",
    "        for chr in chroma: # similar to before, we get a number of time-series\n",
    "            chromaVector.append(statistics(chr)) # and we resolve that by taking statistics over the time series\n",
    "        # Finally, this vector should be be 12 * 7 features\n",
    "        data_chroma.append(np.array(chromaVector).flatten())\n",
    "\n",
    "        bar.update(indexSample)\n",
    "\n",
    "print( \".... done\" + \" (\" + str(datetime.datetime.now()) + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-NN\n",
    "# kd tree was chosen to gain results within a reasonable amount of time\n",
    "\n",
    "def kNN (dataSetName, X_train, X_test, y_train, y_test, n_neighbors_values):\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for n_neighbors in n_neighbors_values:\n",
    "            classifier = KNeighborsClassifier(n_neighbors=n_neighbors, algorithm='kd_tree')\n",
    "\n",
    "            # Train classifier\n",
    "            start_time = datetime.datetime.now()\n",
    "            \n",
    "            #classifier.fit(X_train, y_train.values.ravel())\n",
    "            classifier.fit(X_train, y_train.ravel())\n",
    "\n",
    "            end_time = datetime.datetime.now()\n",
    "            training_time_sec = (end_time - start_time).total_seconds()\n",
    "\n",
    "            # Predict test set on trained classifier\n",
    "            start_time = datetime.datetime.now()\n",
    "            y_test_predicted = classifier.predict(X_test)\n",
    "            end_time = datetime.datetime.now()\n",
    "            testing_time_sec = (end_time - start_time).total_seconds()\n",
    "\n",
    "            # Compute metrics\n",
    "            acc = metrics.accuracy_score(y_test, y_test_predicted)\n",
    "            f1 = f1_score(y_true=y_test, y_pred=y_test_predicted, average='weighted')\n",
    "\n",
    "            # Store results\n",
    "            result = type('',(object,),{'n_neigbors': n_neighbors, 'training_time_sec': training_time_sec, 'testing_time_sec': testing_time_sec, 'acc': acc, 'f1': f1})()\n",
    "            results.append(result)\n",
    "\n",
    "    # Print results\n",
    "    print(dataSetName)\n",
    "    print('Algorithm | acc | f1 | training_time_sec | testing_time_sec')\n",
    "    for res in results:\n",
    "        print('k-NN (' + str(res.n_neigbors) + '-NN) | ' + str(round(res.acc, 3)) + ' | ' + str(round(res.f1, 3)) + ' | ' + str(res.training_time_sec) + ' sec | ' + str(res.testing_time_sec) + ' sec')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(dataSetName, X_train, X_test, y_train, y_test, alpha_values):\n",
    "\n",
    "        results = []\n",
    "\n",
    "        for alpha in alpha_values:\n",
    "                classifier = Perceptron(alpha=alpha, random_state=random_state)\n",
    "\n",
    "                # Train classifier\n",
    "                start_time = datetime.datetime.now()\n",
    "                classifier.fit(X_train, y_train.ravel())\n",
    "                end_time = datetime.datetime.now()\n",
    "                training_time_sec = (end_time - start_time).total_seconds()\n",
    "\n",
    "                # Predict test set on trained classifier\n",
    "                start_time = datetime.datetime.now()\n",
    "                y_test_predicted = classifier.predict(X_test)\n",
    "                end_time = datetime.datetime.now()\n",
    "                testing_time_sec = (end_time - start_time).total_seconds()\n",
    "\n",
    "                # Compute metrics\n",
    "                acc = metrics.accuracy_score(y_test, y_test_predicted)\n",
    "                f1 = f1_score(y_true=y_test, y_pred=y_test_predicted, average='weighted')\n",
    "\n",
    "                # Store results\n",
    "                result = type('',(object,),{'alpha': alpha, 'training_time_sec': training_time_sec, 'testing_time_sec': testing_time_sec, 'acc': acc, 'f1': f1})()\n",
    "                results.append(result)\n",
    "\n",
    "        # Print results\n",
    "        print(dataSetName)\n",
    "        print('Algorithm | acc | f1 | training_time_sec | testing_time_sec')\n",
    "        for res in results:\n",
    "                print('Perceptron (alpha: ' + str(res.alpha) + ') | ' + str(round(res.acc, 3)) + ' | ' + str(round(res.f1, 3)) + ' | ' + str(res.training_time_sec) + ' sec | ' + str(res.testing_time_sec) + ' sec')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "music_bmp\n",
      "Algorithm | acc | f1 | training_time_sec | testing_time_sec\n",
      "Perceptron (alpha: 0.0001) | 0.25 | 0.1 | 0.000986 sec | 0.0 sec\n",
      "Perceptron (alpha: 0.001) | 0.25 | 0.1 | 0.000392 sec | 0.0 sec\n",
      "Perceptron (alpha: 0.01) | 0.25 | 0.1 | 0.001 sec | 0.0 sec\n",
      "\n",
      "music_bmp\n",
      "Algorithm | acc | f1 | training_time_sec | testing_time_sec\n",
      "k-NN (1-NN) | 0.625 | 0.645 | 0.000565 sec | 0.000957 sec\n",
      "k-NN (2-NN) | 0.5 | 0.5 | 0.0 sec | 0.001536 sec\n",
      "k-NN (3-NN) | 0.5 | 0.533 | 0.0 sec | 0.001529 sec\n",
      "\n",
      "music_bpm_statistics\n",
      "Algorithm | acc | f1 | training_time_sec | testing_time_sec\n",
      "Perceptron (alpha: 0.0001) | 0.375 | 0.325 | 0.000999 sec | 0.00097 sec\n",
      "Perceptron (alpha: 0.001) | 0.375 | 0.325 | 0.000998 sec | 0.0 sec\n",
      "Perceptron (alpha: 0.01) | 0.375 | 0.325 | 0.000996 sec | 0.0 sec\n",
      "\n",
      "music_bpm_statistics\n",
      "Algorithm | acc | f1 | training_time_sec | testing_time_sec\n",
      "k-NN (1-NN) | 0.625 | 0.645 | 0.0 sec | 0.000999 sec\n",
      "k-NN (2-NN) | 0.625 | 0.577 | 0.0 sec | 0.002045 sec\n",
      "k-NN (3-NN) | 0.5 | 0.533 | 0.00098 sec | 0.000999 sec\n",
      "\n",
      "music_chroma\n",
      "Algorithm | acc | f1 | training_time_sec | testing_time_sec\n",
      "Perceptron (alpha: 0.0001) | 0.125 | 0.056 | 0.000998 sec | 0.000999 sec\n",
      "Perceptron (alpha: 0.001) | 0.125 | 0.056 | 0.001003 sec | 0.0 sec\n",
      "Perceptron (alpha: 0.01) | 0.125 | 0.056 | 0.00102 sec | 0.0 sec\n",
      "\n",
      "music_chroma\n",
      "Algorithm | acc | f1 | training_time_sec | testing_time_sec\n",
      "k-NN (1-NN) | 0.25 | 0.25 | 0.00101 sec | 0.000998 sec\n",
      "k-NN (2-NN) | 0.375 | 0.405 | 0.0 sec | 0.00103 sec\n",
      "k-NN (3-NN) | 0.25 | 0.1 | 0.0 sec | 0.001999 sec\n",
      "\n",
      "music_mfcc\n",
      "Algorithm | acc | f1 | training_time_sec | testing_time_sec\n",
      "Perceptron (alpha: 0.0001) | 0.75 | 0.767 | 0.001033 sec | 0.0 sec\n",
      "Perceptron (alpha: 0.001) | 0.75 | 0.767 | 0.0 sec | 0.0 sec\n",
      "Perceptron (alpha: 0.01) | 0.75 | 0.767 | 0.001 sec | 0.0 sec\n",
      "\n",
      "music_mfcc\n",
      "Algorithm | acc | f1 | training_time_sec | testing_time_sec\n",
      "k-NN (1-NN) | 0.75 | 0.75 | 0.0 sec | 0.003001 sec\n",
      "k-NN (2-NN) | 0.75 | 0.75 | 0.0 sec | 0.000962 sec\n",
      "k-NN (3-NN) | 0.75 | 0.75 | 0.0 sec | 0.001002 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Finally, we do classification\n",
    "\n",
    "# These are our feature sets; we will use each of them individually to train classifiers\n",
    "trainingSets = [ \n",
    "                 ('music_bmp', data_bpm),\n",
    "                 ('music_bpm_statistics', data_bpm_statistics),\n",
    "                 ('music_chroma', data_chroma),\n",
    "                 ('music_mfcc', data_mfcc)\n",
    "               ]\n",
    "\n",
    "# set up a number of classifiers\n",
    "#classifiers = [neighbors.KNeighborsClassifier(),\n",
    " #              naive_bayes.GaussianNB(),\n",
    "  #             tree.DecisionTreeClassifier(),\n",
    "   #            ensemble.RandomForestClassifier(),\n",
    "    #           svm.SVC(),\n",
    "     #          svm.LinearSVC(),\n",
    "      #        ]\n",
    "\n",
    "def perceptron_music(data_set_name, X_train, X_test, y_train, y_test):\n",
    "    alpha_values = [0.0001, 0.001, 0.01]\n",
    "    perceptron(data_set_name, X_train, X_test, y_train, y_test, alpha_values)\n",
    "\n",
    "def kNN_music(data_set_name, X_train, X_test, y_train, y_test):\n",
    "    n_neighbors_values = [1, 2, 3]\n",
    "    kNN(data_set_name, X_train, X_test, y_train, y_test, n_neighbors_values)\n",
    "      \n",
    "classifiers = [\n",
    "                #('', ),\n",
    "                #('', ),\n",
    "                #('', ),\n",
    "                perceptron_music,\n",
    "                kNN_music\n",
    "              ]\n",
    "\n",
    "data_set_y = target\n",
    "\n",
    "for indexDataset, train_data_set in enumerate(trainingSets):\n",
    "\n",
    "    data_set_X = train_data_set[1]\n",
    "\n",
    "    X, y = shuffle(data_set_X, data_set_y, random_state=random_state)\n",
    "\n",
    "    # Prepare a train/test set split: split 2/3 1/3 into training & test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=random_state)\n",
    "\n",
    "    for indexClassifier, classifier in enumerate(classifiers):\n",
    "        # do the actual classification\n",
    "        classifier(train_data_set[0], X_train, X_test, y_train, y_test)   \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

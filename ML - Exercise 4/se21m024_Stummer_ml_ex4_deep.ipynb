{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "# Exercise 4 - Deep Learning\n",
    "<br/>Student:\n",
    "<br/>se21m024\n",
    "<br/>Matriculation number: 1425616\n",
    "<br/>Thomas Stummer\n",
    "<br/><br/>The interpretation of the data can be found in the document <b><i>se21m024_Stummer_ml_ex4_deep.pdf</i></b>.\n",
    "<br/><br/>\n",
    "The source code was heavily inspired by https://github.com/tuwien-musicir/DeepLearning_Tutorial/ and the code snippets provided by https://www.cs.toronto.edu/~kriz/cifar.html.\n",
    "<br/><br/>\n",
    "Data Set: CIFAR-10<br>\n",
    "\"The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class. The classes are completely mutually exclusive.\" [Description taken from https://www.cs.toronto.edu/~kriz/cifar.html]<br>\n",
    "CIFAR-10 python version downloaded from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz<br>\n",
    "Reference: Learning Multiple Layers of Features from Tiny Images, Alex Krizhevsky, 2009.\n",
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import csv\n",
    "import datetime\n",
    "import glob\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "%matplotlib inline \n",
    "\n",
    "# Matriculation number: 1425616\n",
    "random_state = 1425616\n",
    "np.random.seed(random_state) # we initialize a random seed here to make the experiments repeatable with same results\n",
    "\n",
    "# Fix batch_size and epochs for all tests to make results more comparable\n",
    "batch_size = 32\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Images from the Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported 5 files\n"
     ]
    }
   ],
   "source": [
    "# Unpickle files\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "path = 'cifar-10-batches-py/data_batches'\n",
    "files = glob.glob(os.path.join(path, '*_*'))\n",
    "print('Imported ' + str(len(files)) + ' files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported 50000 images.\n"
     ]
    }
   ],
   "source": [
    "# Import labeled images\n",
    "image_filenames = []\n",
    "images = np.empty([0,3072], dtype=np.ubyte)\n",
    "image_labels = []\n",
    "\n",
    "for filename in files:\n",
    "    file_data = unpickle(filename)\n",
    "    image_filenames.extend(file_data[b'filenames'])\n",
    "    images = np.append(images, file_data[b'data'], axis=0)\n",
    "    image_labels.extend(file_data[b'labels'])\n",
    "    \n",
    "print('Imported ' + str(len(images)) + ' images.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'roe_deer_s_000207.png'\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAHnUlEQVR4nDVW2Y5kyW3lFhF3yayqrpleRi2PRhsECAJsQPoC/T+gLzC0wZI93VXdlXnzxo0ILn4oiQ98InkOeAiS+LNff8fMiIBAxISk0zTpwDF0WfN2+9oOA08RyAJEcD6vROly2dzdzERkXZfWKoBPc3EPUxcRZupD3ZxyzkQEgA4OqNMsxMAC4bhdemh5rU5EIpJzjghELKW4OyJG+PX6UuuuNoiglHw6rcTo4UwIABIRRPTqT6fpdDfp0H1XliCUfT8ikBinaRJBs7HXnUgR+JUWoqckZVpYEMCJo+7b0dr5fBbmeWWJCBGJCOaEmPdbP47mSjnLvjdVA4yUmIl7P4ggSQKg1joAMNM0zWUiFiQKIhxDAePu7iTC7j6aiYiklAK81RpmDlrrbZlnpsRkREoUEdqtTnMpOQ3tPkgojnpQopKyj6bdck4gFIqCCQyHKhG7iwCAqg+tjM7orXUWkYTCdFqnJDy6OUSa0jQXHaO1bgf4iLAAhv267/XKzKUUER5jjDHMnJlTSZhISsn73ohgWhZrIzF3j6fruJvxbl2nsl6v+14Pa3AbrbWmqqBBSESkqmYKgRDoFod2CIhARIJAYeEEcv9wfnm55SwRmFN6c3e61N6vzR3d43Lbtm2PwH4YICIiBgM4vOrrDoCIAkBj2OuAITJARAAEZWbZtoub67DrVt+cpg9vzt+eDMbzPsaX5xdVNwMECHciQsAIj4iIAEAAeEUCAABCDAAgYo9w89u2905ytMpMAGQBtfeJ7d3jfd/rf386nCgLg5BHaG/MGBEQ4UQBCBGvYISCCP+mT+7xysYDR3O5f7gHqK2aQ0yFaVRp9G6lf2wMBnGYYSQpmdPQMcYwB0RiQCbLiYQJgXPivR2Ho3m4mjAhCQFGqLRDE+fIwW4/v79/FJzGeCvpXTn9da9wKloHmIdH650BT6k8Fnh7zsucl4kTAZrfv33/l6fbn/78fwOMKDwczJAoIKTeGoIQyv26zDk/Xb80jofl/Jv7M6B9in6OOCFLYbR0l6c36/mcQqDraGA9M1Pi9xOdP5z7y/M1pr9//lINAxzcRESsd4i+rCeg+N/b5qF4u/2qlI8z/ZZ4S8uEZUY2UgGcSNi1Oh4DurqAKM5G6cfPz+z79+V2LQ8/fvXqREwMjuCSEzJTyWF6XJS88JSWS7Nvip1KXhwhUE3DuwEebMysEeoDwJEkwoTZI172fmkR3M9LrpzMIQFEoDx+OzMzIERX9IjMyzQPxiewB5LYju04jHHKGRl7mPVh/SCCqcwwlFQJ21X1c/cnlQ+Y3szxYnooYIAEyZtvVgRordMky5TCgwgxoLs64Dylo1ekIFcI1LA+RteRlzlnYSLtfWu3G2CbExUpmb/Lpw3rdVjfK5BLAgdEEHSLMF1SyUCZeA6cgdHGPM+UZLS+132Yck4P79+Wh7NH4LDosshCABNLGTb18WY5xWndhyHGddzklx9/wszLum6Xy8vz08N61luNY8QYlz5gGBGtaRIRyrLenb//4YfH//hOE6npuB0zc5nTtu+G1NWu//yff/7tH2/n+7e//MnHj+89uvzx939Qs5yzq20vl6dPn/ayTTlnyWqmqub27tt3Dw/3jjCfVkkJCLsbMed7itE5weP5zMyE+HmdwmCaH374xc/LzAwuZxEnJiRKPCyw6/c//enHjx9FBEWaDiJc5yUiamtHb4YxszBA672URYmUQsfIFJPk9e78u//6T4o0zUWjJ5kp54wIKcte61/+9ndJ+f2H7+Zl1TAkZ4Jwba0+PX/ScUyJl5xyZmYsiRUGJfJjxHDrbgZgIYhTQUK9W9YpJRGRAJim6euXl1TK/cPD6XQaYwBC7z0iWmvKo+T8uukSs6oiAQO7e8oZIiIi52xmOeWImKYSETmJ6hBEZGYze3z8pqQ5pWRmESHMavr6c7zmE1GtVVUjYlmWWusYo/eeU+q9m9k0Tfu+R1hEqNrtdsuZSE1fj/48zymliAAADweAnHMpZZomVW2tAcC6rjnn17sIAGMMMxtjRIS7v4b9+01xVa21CTP33pnZzYiImVNK7tZ6J8Jaa85lnmdV3batlDKGuvsrwGldzR3gtUkREfM8HcdRa22tMQshkfXx+ccfW629t5QIKQAMMGyoKxDw5eul1jY0kIQ45TLNy+ym9XYDc7JInE/LKacSFlMpACEpkaRjKInQaO28ns7rCSEAAzG22xUxhKXkUvKkwy5fL2aGSIgEgO6mOrR3GwPcj6MSEQK01nprEA4QKWciQgjJZUo5q+oYw9z5XyYpwTRlZn58fPj0+TOGu6mbRoSpIzIzt1aZGZBvt2vOZduudXdAWJb1vK4Q0a43cTOI2LYNCVnkVToAYJYxWj30tt/u7taUZN93Rigly7RAxBGho7a2f/P2g7sTwem03K5fEKEdN2LC8N47DR37vpu7iKgqAJQy7fuu2gHj+fmp1n2epzAbrfWjtnpkKcJZRNzttl97r5LoaDXAchIhPPb96/Ozmy13Z1rXtdZbmAqzm26Xr63eEGBoJwJmSiJhNvpRkhAGUpiPbbscx66jL8scCNfry+XyfNuu7hbhRAChx7Exx/8DGpWSqK/H22EAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0x2A21C676FD0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show a selected image to check\n",
    "i=12645\n",
    "print (image_filenames[i])\n",
    "image = images[i]\n",
    "Image.merge('RGB', (\n",
    "    Image.fromarray(np.asarray(np.split(image[0:1024], indices_or_sections=32))),\n",
    "    Image.fromarray(np.asarray(np.split(image[1024:2048], indices_or_sections=32))),\n",
    "    Image.fromarray(np.asarray(np.split(image[2048:3072], indices_or_sections=32)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Groundtruth based on labels:\n",
    "\n",
    "In this data set, all images are labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 25 labels:\n",
      "[6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6, 4, 3, 6, 6, 2]\n",
      "\n",
      "Unique labels:\n",
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
      "\n",
      "Groundtruth Statistics:\n",
      "Label 0 : 5000\n",
      "Label 1 : 5000\n",
      "Label 2 : 5000\n",
      "Label 3 : 5000\n",
      "Label 4 : 5000\n",
      "Label 5 : 5000\n",
      "Label 6 : 5000\n",
      "Label 7 : 5000\n",
      "Label 8 : 5000\n",
      "Label 9 : 5000\n"
     ]
    }
   ],
   "source": [
    "# look at the first 25 classes\n",
    "print('First 25 labels:\\n' + str(image_labels[0:25]) + '\\n')\n",
    "\n",
    "unique_image_labels = set(image_labels)\n",
    "print('Unique labels:\\n' + str(unique_image_labels) + '\\n')\n",
    "\n",
    "print(\"Groundtruth Statistics:\")\n",
    "for v in unique_image_labels:\n",
    "    print(\"Label\", v, \":\", image_labels.count(v))\n",
    "\n",
    "image_classes = np_utils.to_categorical(image_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization\n",
    "\n",
    "Here we use <b>Zero-mean Unit-variance standardization</b> which means we deduct the mean and divide by the standard deviation.\n",
    "\n",
    "(Note: Here, we do this \"flat\", i.e. one mean and std.dev. for the whole image is computed over all pixels (not per pixel); in RGB images, standardization can be done e.g. for each colour channel individually; in other/non-image data sets, attribute-wise standardization should be applied)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 255)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.min(), images.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120.70756512369792, 64.1500758911213)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = images.mean()\n",
    "stddev = images.std()\n",
    "mean, stddev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2.5247951877342226e-17, 1.0000000000000022)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_std = (images - mean) / stddev\n",
    "images_std = np.array(images_std, dtype=float)\n",
    "images_std.mean(), images_std.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.8816433721538972, 2.09341038199596)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_std.min(), images_std.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating NN Models in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1) Fully Connected NN\n",
    "\n",
    "For a fully connected neural network, the x and y axis of an image do not play a role at all. All pixels are considered as a completely individual input to the neural network. Therefore the 2D image arrays have to be flattened to a vector. For our current data set this is already the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072)\n"
     ]
    }
   ],
   "source": [
    "print(images_std.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape for NN: 3072\n"
     ]
    }
   ],
   "source": [
    "# find out input shape for NN, which is just a long vector (32 x 32 x 3 = 1024 x 3 = 3072)\n",
    "input_shape = images_std.shape[1]\n",
    "print('Input shape for NN: ' + str(input_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Model\n",
    "\n",
    "In Keras, one can choose between a Sequential model and a Graph model. Sequential models are the standard case. Graph models are for parallel networks and use the functional API (see Music/Speech tutorial).\n",
    "\n",
    "Here we create a sequential model with 2 fully connected (a.k.a. 'dense') layers containing 256 units each.\n",
    "\n",
    "The output unit is a Single sigmoid unit which can predict values between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_14 (Dense)            (None, 256)               786688    \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 855,050\n",
      "Trainable params: 855,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# simple Fully-connected network\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(256, input_dim=input_shape))\n",
    "model.add(Dense(256, activation='sigmoid'))\n",
    "model.add(Dense(len(unique_image_labels), activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Loss Function and Optimizer Strategy: Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a loss function \n",
    "loss = 'categorical_crossentropy'  # 'categorical_crossentropy' for multi-class problems\n",
    "\n",
    "# Optimizer = Stochastic Gradient Descent\n",
    "optimizer = 'sgd' \n",
    "\n",
    "# Compiling the model\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model on the input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.8184 - accuracy: 0.3654\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.6938 - accuracy: 0.4130\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.6408 - accuracy: 0.4344\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.6028 - accuracy: 0.4499\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.5699 - accuracy: 0.4637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a21c6f3ac0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "model.fit(images_std, image_classes, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 3s 2ms/step\n",
      "Accuracy on training set: 0.47206\n"
     ]
    }
   ],
   "source": [
    "# verify accuracy on train set\n",
    "predictions = model.predict(images_std)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "image_labels_for_comparison = np.array(image_labels)\n",
    "accuracy_on_training_set = accuracy_score(image_labels_for_comparison, predicted_classes)\n",
    "print('Accuracy on training set: ' + str(accuracy_on_training_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the accuracy on the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with Test Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported 1 files.\n",
      "Imported 10000 images.\n",
      "Groundtruth Statistics:\n",
      "Label 0 : 1000\n",
      "Label 1 : 1000\n",
      "Label 2 : 1000\n",
      "Label 3 : 1000\n",
      "Label 4 : 1000\n",
      "Label 5 : 1000\n",
      "Label 6 : 1000\n",
      "Label 7 : 1000\n",
      "Label 8 : 1000\n",
      "Label 9 : 1000\n"
     ]
    }
   ],
   "source": [
    "# Unpickle files\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "path = 'cifar-10-batches-py/test_batches'\n",
    "files = glob.glob(os.path.join(path, '*_*'))\n",
    "print('Imported ' + str(len(files)) + ' files.')\n",
    "\n",
    "# Import labeled images\n",
    "test_image_filenames = []\n",
    "test_images = np.empty([0,3072], dtype=np.ubyte)\n",
    "test_image_labels = []\n",
    "\n",
    "for filename in files:\n",
    "    file_data = unpickle(filename)\n",
    "    test_image_filenames.extend(file_data[b'filenames'])\n",
    "    test_images = np.append(test_images, file_data[b'data'], axis=0)\n",
    "    test_image_labels.extend(file_data[b'labels'])\n",
    "    \n",
    "test_image_labels_for_comparison = np.array(test_image_labels)\n",
    "test_image_classes = np_utils.to_categorical(test_image_labels)\n",
    "\n",
    "print('Imported ' + str(len(test_images)) + ' images.')\n",
    "\n",
    "print(\"Groundtruth Statistics:\")\n",
    "for v in unique_image_labels:\n",
    "    print(\"Label\", v, \":\", test_image_labels.count(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize Test Set\n",
    "\n",
    "The test data has to be standardized <b>in the same way</b> as the training data for compatibility with the model! That means, we take the mean and standard deviation of the <i>training data</i> to transform also the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NO! we take the same mean and stddev from the training data above!\n",
    "#mean = test_images.mean()\n",
    "#stddev = test_images.std()\n",
    "#print mean, stddev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121.52915475260417, 64.06097012299574)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.mean(), test_images.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_images_std = (test_images - mean) / stddev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.012807305642173993, 0.9986109795368484)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images_std.mean(), test_images_std.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n",
      "Accuracy on test set: 0.4498\n"
     ]
    }
   ],
   "source": [
    "# verify accuracy on test set\n",
    "test_predictions = model.predict(test_images_std)\n",
    "test_predicted_classes = np.argmax(test_predictions, axis=1)\n",
    "accuracy_on_test_set = accuracy_score(test_image_labels_for_comparison, test_predicted_classes)\n",
    "print('Accuracy on test set: ' + str(accuracy_on_test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Convolutional Neural Network\n",
    "\n",
    "A Convolutional Neural Network (ConvNet or CNN) is a type of (deep) Neural Network that is well-suited for 2D axes data, such as images, as it is optimized for learning from spatial proximity. Its core elements are 2D filter kernels which essentially learn the weights of the Neural Network, and downscaling functions such as Max Pooling.\n",
    "\n",
    "A CNN can have one or more Convolution layers, each of them having an arbitrary number of N filters (which define the depth of the CNN layer), following typically by a pooling step, which groups neighboring pixels together and thus reduces the image resolution by retaining only the maximum values of neighboring pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input\n",
    "\n",
    "Our input to the CNN is the standardized version of the original image array.\n",
    "\n",
    "#### Adding the channel\n",
    "\n",
    "For CNNs, we need to add a dimension for the color channel to the data. RGB images typically have an 3rd dimension with the color. \n",
    "<b>For greyscale images we need to add an extra dimension for compatibility with the CNN implementation.</b>\n",
    "\n",
    "In Theano, traditionally the color channel was the <b>first</b> dimension in the image shape. \n",
    "In Tensorflow, the color channel is the <b>last</b> dimension in the image shape. \n",
    "\n",
    "This can be configured now in ~/.keras/keras.json: \"image_dim_ordering\": \"th\" or \"tf\" with \"tf\" (Tensorflow) being the default image ordering even though you use Theano. Depending on this, use one of the code lines below.\n",
    "\n",
    "For greyscale images, we add the number 1 as the depth of the additional dimension of the input shape (for RGB color images, the number of channels is 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_channels = 3 # for grey-scale, 3 for RGB, but usually already present in the data\n",
    "edge_pixels = 32\n",
    "\n",
    "keras.backend.set_image_data_format('channels_last')\n",
    "train_img = images_std.reshape(images_std.shape[0], edge_pixels, edge_pixels, n_channels)\n",
    "test_img = test_images_std.reshape(test_images_std.shape[0], edge_pixels, edge_pixels, n_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072)\n",
      "(10000, 3072)\n",
      "(50000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(images_std.shape)\n",
    "print(test_images_std.shape)\n",
    "print(train_img.shape)\n",
    "print(test_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we store the new shape of the images in the 'input_shape' variable.\n",
    "# take all dimensions except the 0th one (which is the number of images)\n",
    "    \n",
    "input_shape = train_img.shape[1:]  \n",
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the CNN model\n",
    "\n",
    "You may try to change the following to see the impact on the result:\n",
    "* number of filters\n",
    "* filter kernel size (e.g. 3 x 3, 5 x 5, ...)\n",
    "* adding/not adding Batch Normalization\n",
    "* adding/not adding ReLU Activation\n",
    "* adding/not adding Max Pooling\n",
    "* changing Pooling size (e.g. 1 x 2, 2 x 2, 2 x 1, or more)\n",
    "* adding/changing/removing Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def createMyModel():\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Convolution2D(64, (3,3), input_shape=input_shape, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Convolution2D(64, (3,3), activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Convolution2D(64, (3,3), activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "\n",
    "    model.add(Dense(len(unique_image_labels), activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_30 (Conv2D)          (None, 30, 30, 64)        1792      \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 30, 30, 64)        0         \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 28, 28, 64)        36928     \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 28, 28, 64)        0         \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 26, 26, 64)        36928     \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 26, 26, 64)        0         \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 43264)             0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 128)               5537920   \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,614,858\n",
      "Trainable params: 5,614,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = createMyModel()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "loss = 'categorical_crossentropy' \n",
    "optimizer = 'sgd' \n",
    "#optimizer = SGD(lr=0.001)  # possibility to adapt the learn rate\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 254s 162ms/step - loss: 1.6399 - accuracy: 0.4148\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 258s 165ms/step - loss: 1.3326 - accuracy: 0.5313\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 249s 159ms/step - loss: 1.1857 - accuracy: 0.5833\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 245s 157ms/step - loss: 1.0748 - accuracy: 0.6242\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 251s 160ms/step - loss: 0.9705 - accuracy: 0.6615\n"
     ]
    }
   ],
   "source": [
    "# TRAINING the model\n",
    "history = model.fit(train_img, image_classes, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying Accuracy on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 8s 26ms/step\n",
      "Accuracy on test set: 0.6364\n"
     ]
    }
   ],
   "source": [
    "# verify accuracy on test set\n",
    "predictions = model.predict(test_img)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "accuracy_on_test_set = accuracy_score(test_image_labels_for_comparison, predicted_classes)\n",
    "print('Accuracy on test set: ' + str(accuracy_on_test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the Training Curve\n",
    "\n",
    "The `model.fit` function returns a history including the evolution of training with loss and accuracy. We can plot it to see a nice training curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy'])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = history.history\n",
    "hist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2a21aa78d90>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = {'loss':'r', 'accuracy':'b'}\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title(\"Training Curve\") \n",
    "plt.xlabel(\"Epoch\")\n",
    "\n",
    "for measure in hist.keys():\n",
    "    color = colors[measure]\n",
    "    plt.plot(range(1,epochs+1), hist[measure], color + '-', label=measure)  # use last 2 values to draw line\n",
    "\n",
    "plt.legend(loc='upper left', scatterpoints = 1, frameon=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data Augmentation\n",
    "\n",
    "Increase the training set by adding more images: Rotate, shift, flip and scale the original images to generate additional examples that will help the Neural Network to generalize better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 264s 168ms/step - loss: 2.0223 - accuracy: 0.2544\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 263s 168ms/step - loss: 1.8591 - accuracy: 0.3134\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 261s 167ms/step - loss: 1.7978 - accuracy: 0.3397\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 261s 167ms/step - loss: 1.7556 - accuracy: 0.3572\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 261s 167ms/step - loss: 1.7122 - accuracy: 0.3730\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# recreate and recompile the model (otherwise we continue learning)\n",
    "model = createMyModel()\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "history = model.fit(datagen.flow(train_img, image_classes, batch_size=batch_size),\n",
    "                    epochs=epochs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying Accuracy on Test Set (with Data Augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 10s 32ms/step\n",
      "Accuracy on test set with augmentation: 0.3495\n"
     ]
    }
   ],
   "source": [
    "# verify accuracy on test set with augmentation\n",
    "predictions = model.predict(test_img)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "accuracy_on_test_set = accuracy_score(test_image_labels_for_comparison, predicted_classes)\n",
    "print('Accuracy on test set with augmentation: ' + str(accuracy_on_test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Plotting the Training Curve with Data Augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2a203f2ca90>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist = history.history\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title(\"Training Curve\") \n",
    "plt.xlabel(\"Epoch\")\n",
    "\n",
    "for measure in hist.keys():\n",
    "    color = colors[measure]\n",
    "    plt.plot(range(1,epochs+1), hist[measure], color + '-', label=measure)  # use last 2 values to draw line\n",
    "\n",
    "plt.legend(loc='upper left', scatterpoints = 1, frameon=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
